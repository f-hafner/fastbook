{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[chapter_collab]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Deep Dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One very common problem to solve is when you have a number of users and a number of products, and you want to recommend which products are most likely to be useful for which users. There are many variations of this: for example, recommending movies (such as on Netflix), figuring out what to highlight for a user on a home page, deciding what stories to show in a social media feed, and so forth. There is a general solution to this problem, called *collaborative filtering*, which works like this: look at what products the current user has used or liked, find other users that have used or liked similar products, and then recommend other products that those users have used or liked.\n",
    "\n",
    "For example, on Netflix you may have watched lots of movies that are science fiction, full of action, and were made in the 1970s. Netflix may not know these particular properties of the films you have watched, but it will be able to see that other people that have watched the same movies that you watched also tended to watch other movies that are science fiction, full of action, and were made in the 1970s. In other words, to use this approach we don't necessarily need to know anything about the movies, except who like to watch them.\n",
    "\n",
    "There is actually a more general class of problems that this approach can solve, not necessarily involving users and products. Indeed, for collaborative filtering we more commonly refer to *items*, rather than *products*. Items could be links that people click on, diagnoses that are selected for patients, and so forth.\n",
    "\n",
    "The key foundational idea is that of *latent factors*. In the Netflix example, we started with the assumption that you like old, action-packed sci-fi movies. But you never actually told Netflix that you like these kinds of movies. And Netflix never actually needed to add columns to its movies table saying which movies are of these types. Still, there must be some underlying concept of sci-fi, action, and movie age, and these concepts must be relevant for at least some people's movie watching decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this chapter we are going to work on this movie recommendation problem. We'll start by getting some data suitable for a collaborative filtering model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A First Look at the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not have access to Netflix's entire dataset of movie watching history, but there is a great dataset that we can use, called [MovieLens](https://grouplens.org/datasets/movielens/). This dataset contains tens of millions of movie rankings (a combination of a movie ID, a user ID, and a numeric rating), although we will just use a subset of 100,000 of them for our example. If you're interested, it would be a great learning project to try and replicate this approach on the full 25-million recommendation dataset, which you can get from their website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is available through the usual fastai function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='4931584' class='' max='4924029' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.15% [4931584/4924029 00:01&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.collab import *\n",
    "from fastai.tabular.all import *\n",
    "path = untar_data(URLs.ML_100k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the *README*, the main table is in the file *u.data*. It is tab-separated and the columns are, respectively user, movie, rating, and timestamp. Since those names are not encoded, we need to indicate them when reading the file with Pandas. Here is a way to open this table and take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  movie  rating  timestamp\n",
       "0   196    242       3  881250949\n",
       "1   186    302       3  891717742\n",
       "2    22    377       1  878887116\n",
       "3   244     51       2  880606923\n",
       "4   166    346       1  886397596"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(path/'u.data', delimiter='\\t', header=None,\n",
    "                      names=['user','movie','rating','timestamp'])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this has all the information we need, it is not a particularly helpful way for humans to look at this data. <<movie_xtab>> shows the same data cross-tabulated into a human-friendly table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Crosstab of movies and users\" width=\"632\" caption=\"Crosstab of movies and users\" id=\"movie_xtab\" src=\"images/att_00040.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have selected just a few of the most popular movies, and users who watch the most movies, for this crosstab example. The empty cells in this table are the things that we would like our model to learn to fill in. Those are the places where a user has not reviewed the movie yet, presumably because they have not watched it. For each user, we would like to figure out which of those movies they might be most likely to enjoy.\n",
    "\n",
    "If we knew for each user to what degree they liked each important category that a movie might fall into, such as genre, age, preferred directors and actors, and so forth, and we knew the same information about each movie, then a simple way to fill in this table would be to multiply this information together for each movie and use a combination. For instance, assuming these factors range between -1 and +1, with positive numbers indicating stronger matches and negative numbers weaker ones, and the categories are science-fiction, action, and old movies, then we could represent the movie *The Last Skywalker* as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_skywalker = np.array([0.98,0.9,-0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, for instance, we are scoring *very science-fiction* as 0.98, *very action* as 0.9, and *very not old* as -0.9. We could represent a user who likes modern sci-fi action movies as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1 = np.array([0.9,0.8,-0.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can now calculate the match between this combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1420000000000003"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(user1*last_skywalker).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we multiply two vectors together and add up the results, this is known as the *dot product*. It is used a lot in machine learning, and forms the basis of matrix multiplication. We will be looking a lot more at matrix multiplication and dot products in <<chapter_foundations>>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> jargon: dot product: The mathematical operation of multiplying the elements of two vectors together, and then summing up the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, we might represent the movie *Casablanca* as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "casablanca = np.array([-0.99,-0.3,0.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The match between this combination is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.611"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(user1*casablanca).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't know what the latent factors actually are, and we don't know how to score them for each user and movie, we should learn them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the Latent Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is surprisingly little difference between specifying the structure of a model, as we did in the last section, and learning one, since we can just use our general gradient descent approach.\n",
    "\n",
    "Step 1 of this approach is to randomly initialize some parameters. These parameters will be a set of latent factors for each user and movie. We will have to decide how many to use. We will discuss how to select this shortly, but for illustrative purposes let's use 5 for now. Because each user will have a set of these factors and each movie will have a set of these factors, we can show these randomly initialized values right next to the users and movies in our crosstab, and we can then fill in the dot products for each of these combinations in the middle. For example, <<xtab_latent>> shows what it looks like in Microsoft Excel, with the top-left cell formula displayed as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Latent factors with crosstab\" width=\"900\" caption=\"Latent factors with crosstab\" id=\"xtab_latent\" src=\"images/att_00041.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 of this approach is to calculate our predictions. As we've discussed, we can do this by simply taking the dot product of each movie with each user. If, for instance, the first latent user factor represents how much the user likes action movies and the first latent movie factor represents if the movie has a lot of action or not, the product of those will be particularly high if either the user likes action movies and the movie has a lot of action in it or the user doesn't like action movies and the movie doesn't have any action in it. On the other hand, if we have a mismatch (a user loves action movies but the movie isn't an action film, or the user doesn't like action movies and it is one), the product will be very low.\n",
    "\n",
    "Step 3 is to calculate our loss. We can use any loss function that we wish; let's pick mean squared error for now, since that is one reasonable way to represent the accuracy of a prediction.\n",
    "\n",
    "That's all we need. With this in place, we can optimize our parameters (that is, the latent factors) using stochastic gradient descent, such as to minimize the loss. At each step, the stochastic gradient descent optimizer will calculate the match between each movie and each user using the dot product, and will compare it to the actual rating that each user gave to each movie. It will then calculate the derivative of this value and will step the weights by multiplying this by the learning rate. After doing this lots of times, the loss will get better and better, and the recommendations will also get better and better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the usual `Learner.fit` function we will need to get our data into a `DataLoaders`, so let's focus on that now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When showing the data, we would rather see movie titles than their IDs. The table `u.item` contains the correspondence of IDs to titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie              title\n",
       "0      1   Toy Story (1995)\n",
       "1      2   GoldenEye (1995)\n",
       "2      3  Four Rooms (1995)\n",
       "3      4  Get Shorty (1995)\n",
       "4      5     Copycat (1995)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(path/'u.item',  delimiter='|', encoding='latin-1',\n",
    "                     usecols=(0,1), names=('movie','title'), header=None)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can merge this with our `ratings` table to get the user ratings by title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>Heavyweights (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>Legends of the Fall (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>Jackie Brown (1997)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  movie  rating  timestamp                       title\n",
       "0   196    242       3  881250949                Kolya (1996)\n",
       "1   186    302       3  891717742    L.A. Confidential (1997)\n",
       "2    22    377       1  878887116         Heavyweights (1994)\n",
       "3   244     51       2  880606923  Legends of the Fall (1994)\n",
       "4   166    346       1  886397596         Jackie Brown (1997)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = ratings.merge(movies)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then build a `DataLoaders` object from this table. By default, it takes the first column for the user, the second column for the item (here our movies), and the third column for the ratings. We need to change the value of `item_name` in our case to use the titles instead of the IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>782</td>\n",
       "      <td>Starship Troopers (1997)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>943</td>\n",
       "      <td>Judge Dredd (1995)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>758</td>\n",
       "      <td>Mission: Impossible (1996)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>Farewell My Concubine (1993)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>Psycho (1960)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>296</td>\n",
       "      <td>Secrets &amp; Lies (1996)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>940</td>\n",
       "      <td>American President, The (1995)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>334</td>\n",
       "      <td>Star Trek VI: The Undiscovered Country (1991)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>380</td>\n",
       "      <td>Braveheart (1995)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>690</td>\n",
       "      <td>So I Married an Axe Murderer (1993)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=64)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To represent collaborative filtering in PyTorch we can't just use the crosstab representation directly, especially if we want it to fit into our deep learning framework. We can represent our movie and user latent factor tables as simple matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': ['#na#', 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943],\n",
       " 'title': ['#na#', \"'Til There Was You (1997)\", '1-900 (1994)', '101 Dalmatians (1996)', '12 Angry Men (1957)', '187 (1997)', '2 Days in the Valley (1996)', '20,000 Leagues Under the Sea (1954)', '2001: A Space Odyssey (1968)', '3 Ninjas: High Noon At Mega Mountain (1998)', '39 Steps, The (1935)', '8 1/2 (1963)', '8 Heads in a Duffel Bag (1997)', '8 Seconds (1994)', 'A Chef in Love (1996)', 'Above the Rim (1994)', 'Absolute Power (1997)', 'Abyss, The (1989)', 'Ace Ventura: Pet Detective (1994)', 'Ace Ventura: When Nature Calls (1995)', 'Across the Sea of Time (1995)', 'Addams Family Values (1993)', 'Addicted to Love (1997)', 'Addiction, The (1995)', 'Adventures of Pinocchio, The (1996)', 'Adventures of Priscilla, Queen of the Desert, The (1994)', 'Adventures of Robin Hood, The (1938)', 'Affair to Remember, An (1957)', 'African Queen, The (1951)', 'Afterglow (1997)', 'Age of Innocence, The (1993)', 'Aiqing wansui (1994)', 'Air Bud (1997)', 'Air Force One (1997)', 'Air Up There, The (1994)', 'Airheads (1994)', 'Akira (1988)', 'Aladdin (1992)', 'Aladdin and the King of Thieves (1996)', 'Alaska (1996)', 'Albino Alligator (1996)', 'Alice in Wonderland (1951)', 'Alien (1979)', 'Alien 3 (1992)', 'Alien: Resurrection (1997)', 'Aliens (1986)', 'All About Eve (1950)', 'All Dogs Go to Heaven 2 (1996)', 'All Over Me (1997)', 'All Things Fair (1996)', 'Alphaville (1965)', 'Amadeus (1984)', 'Amateur (1994)', 'Amazing Panda Adventure, The (1995)', 'American Buffalo (1996)', 'American Dream (1990)', 'American President, The (1995)', 'American Strays (1996)', 'American Werewolf in London, An (1981)', 'American in Paris, An (1951)', 'Amistad (1997)', \"Amityville 1992: It's About Time (1992)\", 'Amityville 3-D (1983)', 'Amityville Curse, The (1990)', 'Amityville Horror, The (1979)', 'Amityville II: The Possession (1982)', 'Amityville: A New Generation (1993)', 'Amityville: Dollhouse (1996)', 'Amos & Andrew (1993)', 'An Unforgettable Summer (1994)', 'Anaconda (1997)', 'Anastasia (1997)', 'Andre (1994)', 'Angel Baby (1995)', 'Angel and the Badman (1947)', 'Angel on My Shoulder (1946)', 'Angela (1995)', 'Angels and Insects (1995)', 'Angels in the Outfield (1994)', 'Angus (1995)', 'Anna (1996)', 'Anna Karenina (1997)', 'Anne Frank Remembered (1995)', 'Annie Hall (1977)', 'Another Stakeout (1993)', \"Antonia's Line (1995)\", 'Aparajito (1956)', 'Apartment, The (1960)', 'Apocalypse Now (1979)', 'Apollo 13 (1995)', 'Apostle, The (1997)', 'Apple Dumpling Gang, The (1975)', \"April Fool's Day (1986)\", 'Apt Pupil (1998)', 'Aristocats, The (1970)', 'Army of Darkness (1993)', 'Around the World in 80 Days (1956)', 'Arrival, The (1996)', 'Arsenic and Old Lace (1944)', 'As Good As It Gets (1997)', 'Assassins (1995)', 'Assignment, The (1997)', 'Associate, The (1996)', 'Audrey Rose (1977)', 'August (1996)', 'Austin Powers: International Man of Mystery (1997)', 'Awfully Big Adventure, An (1995)', 'Ayn Rand: A Sense of Life (1997)', 'B*A*P*S (1997)', 'B. Monkey (1998)', 'Babe (1995)', 'Baby-Sitters Club, The (1995)', 'Babyfever (1994)', 'Babysitter, The (1995)', 'Back to the Future (1985)', 'Backbeat (1993)', 'Bad Boys (1995)', 'Bad Company (1995)', 'Bad Girls (1994)', 'Bad Moon (1996)', 'Bad Taste (1987)', 'Ballad of Narayama, The (Narayama Bushiko) (1958)', 'Balto (1995)', 'Bananas (1971)', 'Band Wagon, The (1953)', 'Barb Wire (1996)', 'Barbarella (1968)', 'Barcelona (1994)', 'Basic Instinct (1992)', 'Basketball Diaries, The (1995)', 'Basquiat (1996)', 'Bastard Out of Carolina (1996)', 'Batman & Robin (1997)', 'Batman (1989)', 'Batman Forever (1995)', 'Batman Returns (1992)', 'Baton Rouge (1988)', 'Bean (1997)', 'Beans of Egypt, Maine, The (1994)', 'Beat the Devil (1954)', 'Beautician and the Beast, The (1997)', 'Beautiful Girls (1996)', 'Beautiful Thing (1996)', 'Beauty and the Beast (1991)', 'Beavis and Butt-head Do America (1996)', 'Bed of Roses (1996)', 'Bedknobs and Broomsticks (1971)', 'Before Sunrise (1995)', 'Before and After (1996)', 'Before the Rain (Pred dozhdot) (1994)', 'Being Human (1993)', 'Being There (1979)', 'Believers, The (1987)', 'Belle de jour (1967)', 'Ben-Hur (1959)', 'Benny & Joon (1993)', 'Bent (1997)', 'Best Men (1997)', 'Best of the Best 3: No Turning Back (1995)', 'Better Off Dead... (1985)', 'Beverly Hillbillies, The (1993)', 'Beverly Hills Cop III (1994)', 'Beverly Hills Ninja (1997)', 'Bewegte Mann, Der (1994)', 'Beyond Bedlam (1993)', 'Beyond Rangoon (1995)', 'Bhaji on the Beach (1993)', 'Big Bang Theory, The (1994)', 'Big Blue, The (Grand bleu, Le) (1988)', 'Big Bully (1996)', 'Big Green, The (1995)', 'Big Lebowski, The (1998)', 'Big Night (1996)', 'Big One, The (1997)', 'Big Sleep, The (1946)', 'Big Squeeze, The (1996)', 'Billy Madison (1995)', 'Bio-Dome (1996)', 'Bird of Prey (1996)', 'Birdcage, The (1996)', 'Birds, The (1963)', 'Bitter Moon (1992)', 'Bitter Sugar (Azucar Amargo) (1996)', 'Black Beauty (1994)', 'Black Sheep (1996)', 'Blade Runner (1982)', 'Blink (1994)', 'Bliss (1997)', 'Blob, The (1958)', 'Blood & Wine (1997)', 'Blood Beach (1981)', \"Blood For Dracula (Andy Warhol's Dracula) (1974)\", 'Bloodsport 2 (1995)', 'Bloody Child, The (1996)', 'Blown Away (1994)', 'Blue Angel, The (Blaue Engel, Der) (1930)', 'Blue Chips (1994)', 'Blue Sky (1994)', 'Blue in the Face (1995)', 'Blues Brothers 2000 (1998)', 'Blues Brothers, The (1980)', 'Bob Roberts (1992)', 'Body Parts (1991)', 'Body Snatcher, The (1945)', 'Body Snatchers (1993)', 'Bogus (1996)', 'Bonheur, Le (1965)', 'Bonnie and Clyde (1967)', 'Boogie Nights (1997)', 'Boomerang (1992)', 'Boot, Das (1981)', 'Booty Call (1997)', 'Bottle Rocket (1996)', 'Bound (1996)', 'Boxing Helena (1993)', \"Boy's Life 2 (1997)\", 'Boys (1996)', 'Boys Life (1995)', 'Boys in Venice (1996)', 'Boys of St. Vincent, The (1993)', 'Boys on the Side (1995)', 'Boys, Les (1997)', 'Brady Bunch Movie, The (1995)', 'Braindead (1992)', \"Bram Stoker's Dracula (1992)\", 'Brassed Off (1996)', 'Braveheart (1995)', 'Brazil (1985)', 'Bread and Chocolate (Pane e cioccolata) (1973)', 'Breakdown (1997)', \"Breakfast at Tiffany's (1961)\", 'Breaking the Waves (1996)', 'Bride of Frankenstein (1935)', 'Bridge on the River Kwai, The (1957)', 'Bridges of Madison County, The (1995)', 'Bringing Up Baby (1938)', 'Broken Arrow (1996)', 'Broken English (1996)', 'Bronx Tale, A (1993)', 'Brother Minister: The Assassination of Malcolm X (1994)', \"Brother's Kiss, A (1997)\", 'Brothers McMullen, The (1995)', 'Brothers in Trouble (1995)', 'Browning Version, The (1994)', 'Buddy (1997)', 'Bulletproof (1996)', 'Bullets Over Broadway (1994)', 'Burnt By the Sun (1994)', 'Burnt Offerings (1976)', 'Bushwhacked (1995)', 'Butch Cassidy and the Sundance Kid (1969)', 'Butcher Boy, The (1998)', 'Butterfly Kiss (1995)', 'Bye Bye, Love (1995)', \"C'est arrivé près de chez vous (1992)\", 'Cabin Boy (1994)', 'Cable Guy, The (1996)', 'Calendar Girl (1993)', 'Canadian Bacon (1994)', 'Candidate, The (1972)', 'Candyman (1992)', 'Candyman: Farewell to the Flesh (1995)', 'Cape Fear (1962)', 'Cape Fear (1991)', 'Captives (1994)', 'Career Girls (1997)', 'Careful (1992)', \"Carlito's Way (1993)\", 'Carmen Miranda: Bananas Is My Business (1994)', 'Caro Diario (Dear Diary) (1994)', 'Carpool (1996)', 'Carrie (1976)', 'Carried Away (1996)', 'Carrington (1995)', 'Casablanca (1942)', 'Casino (1995)', 'Casper (1995)', 'Castle Freak (1995)', 'Cat People (1982)', 'Cat on a Hot Tin Roof (1958)', \"Cats Don't Dance (1997)\", 'Catwalk (1995)', 'Caught (1996)', 'Celestial Clockwork (1994)', 'Celluloid Closet, The (1995)', 'Celtic Pride (1996)', 'Cement Garden, The (1993)', 'Cemetery Man (Dellamorte Dellamore) (1994)', 'Century (1993)', 'Chain Reaction (1996)', 'Chairman of the Board (1998)', 'Chamber, The (1996)', 'Charade (1963)', 'Chasers (1994)', 'Chasing Amy (1997)', 'Children of the Corn: The Gathering (1996)', 'Children of the Revolution (1996)', 'Chinatown (1974)', 'Christmas Carol, A (1938)', 'Chungking Express (1994)', 'Ciao, Professore! (1993)', 'Cinderella (1950)', 'Cinema Paradiso (1988)', 'Circle of Friends (1995)', 'Citizen Kane (1941)', 'Citizen Ruth (1996)', 'City Hall (1996)', \"City Slickers II: The Legend of Curly's Gold (1994)\", 'City of Angels (1998)', 'City of Industry (1997)', 'City of Lost Children, The (1995)', 'Clean Slate (1994)', 'Clean Slate (Coup de Torchon) (1981)', 'Clear and Present Danger (1994)', 'Clerks (1994)', 'Client, The (1994)', 'Cliffhanger (1993)', 'Clockers (1995)', 'Clockwork Orange, A (1971)', 'Close Shave, A (1995)', 'Clueless (1995)', 'Cobb (1994)', 'Cold Comfort Farm (1995)', 'Coldblooded (1995)', 'Collectionneuse, La (1967)', 'Colonel Chabert, Le (1994)', 'Color of Night (1994)', 'Commandments (1997)', 'Con Air (1997)', 'Conan the Barbarian (1981)', 'Condition Red (1995)', 'Coneheads (1993)', 'Congo (1995)', 'Conspiracy Theory (1997)', 'Contact (1997)', 'Contempt (Mépris, Le) (1963)', 'Convent, The (Convento, O) (1995)', 'Cook the Thief His Wife & Her Lover, The (1989)', 'Cool Hand Luke (1967)', 'Cool Runnings (1993)', 'Cop Land (1997)', 'Cops and Robbersons (1994)', 'Copycat (1995)', 'Corrina, Corrina (1994)', 'Cosi (1996)', 'Country Life (1994)', 'Courage Under Fire (1996)', 'Cowboy Way, The (1994)', 'Craft, The (1996)', 'Crash (1996)', 'Crimson Tide (1995)', 'Critical Care (1997)', 'Cronos (1992)', 'Crooklyn (1994)', 'Crossfire (1947)', 'Crossing Guard, The (1995)', 'Crow, The (1994)', 'Crow: City of Angels, The (1996)', 'Crows and Sparrows (1949)', 'Crucible, The (1996)', 'Crude Oasis, The (1995)', 'Crumb (1994)', 'Cry, the Beloved Country (1995)', 'Crying Game, The (1992)', 'Curdled (1996)', 'Cure, The (1995)', 'Cutthroat Island (1995)', 'Cyclo (1995)', 'Cyrano de Bergerac (1990)', 'Cérémonie, La (1995)', 'D3: The Mighty Ducks (1996)', 'Dadetown (1995)', 'Daens (1992)', 'Damsel in Distress, A (1937)', 'Dances with Wolves (1990)', 'Dangerous Beauty (1998)', 'Dangerous Ground (1997)', 'Dangerous Minds (1995)', \"Daniel Defoe's Robinson Crusoe (1996)\", \"Dante's Peak (1997)\", 'Dark City (1998)', 'Dave (1993)', 'Davy Crockett, King of the Wild Frontier (1955)', 'Day the Earth Stood Still, The (1951)', 'Day the Sun Turned Cold, The (Tianguo niezi) (1994)', 'Daylight (1996)', 'Days of Thunder (1990)', 'Daytrippers, The (1996)', 'Dazed and Confused (1993)', 'Dead Man (1995)', 'Dead Man Walking (1995)', 'Dead Poets Society (1989)', 'Dead Presidents (1995)', 'Dear God (1996)', 'Death and the Maiden (1994)', 'Death in Brunswick (1991)', 'Death in the Garden (Mort en ce jardin, La) (1956)', 'Deceiver (1997)', 'Deconstructing Harry (1997)', 'Deep Rising (1998)', 'Deer Hunter, The (1978)', 'Delicatessen (1991)', 'Delta of Venus (1994)', 'Demolition Man (1993)', 'Denise Calls Up (1995)', 'Desert Winds (1995)', 'Designated Mourner, The (1997)', 'Desperado (1995)', 'Desperate Measures (1998)', 'Destiny Turns on the Radio (1995)', 'Devil in a Blue Dress (1995)', \"Devil's Advocate, The (1997)\", \"Devil's Own, The (1997)\", 'Diabolique (1996)', 'Dial M for Murder (1954)', 'Die Hard (1988)', 'Die Hard 2 (1990)', 'Die Hard: With a Vengeance (1995)', 'Die xue shuang xiong (Killer, The) (1989)', 'Dingo (1992)', 'Dirty Dancing (1987)', 'Disclosure (1994)', 'Diva (1981)', 'Dolores Claiborne (1994)', 'Don Juan DeMarco (1995)', \"Don't Be a Menace to South Central While Drinking Your Juice in the Hood (1996)\", 'Donnie Brasco (1997)', 'Doom Generation, The (1995)', 'Doors, The (1991)', 'Double Happiness (1994)', 'Double Team (1997)', 'Double vie de Véronique, La (Double Life of Veronique, The) (1991)', 'Down Periscope (1996)', 'Down by Law (1986)', 'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)', 'Dracula: Dead and Loving It (1995)', 'Dragonheart (1996)', 'Dream Man (1995)', 'Dream With the Fishes (1997)', 'Drop Dead Fred (1991)', 'Drop Zone (1994)', 'Drunks (1995)', 'Duck Soup (1933)', 'Dumb & Dumber (1994)', 'Dumbo (1941)', 'Dunston Checks In (1996)', 'Duoluo tianshi (1995)', 'E.T. the Extra-Terrestrial (1982)', 'East of Eden (1955)', 'Eat Drink Man Woman (1994)', 'Ed (1996)', 'Ed Wood (1994)', \"Ed's Next Move (1996)\", 'Eddie (1996)', 'Edge, The (1997)', 'Eighth Day, The (1996)', 'Emma (1996)', 'Empire Strikes Back, The (1980)', 'Enchanted April (1991)', 'Endless Summer 2, The (1994)', \"Enfer, L' (1994)\", 'English Patient, The (1996)', 'Englishman Who Went Up a Hill, But Came Down a Mountain, The (1995)', 'Entertaining Angels: The Dorothy Day Story (1996)', 'Eraser (1996)', 'Escape from L.A. (1996)', 'Escape from New York (1981)', 'Escape to Witch Mountain (1975)', 'Etz Hadomim Tafus (Under the Domin Tree) (1994)', \"Eve's Bayou (1997)\", 'Even Cowgirls Get the Blues (1993)', 'Evening Star, The (1996)', 'Event Horizon (1997)', 'Everest (1998)', 'Every Other Weekend (1990)', 'Everyone Says I Love You (1996)', 'Evil Dead II (1987)', 'Evita (1996)', 'Excess Baggage (1997)', 'Executive Decision (1996)', 'Exit to Eden (1994)', 'Exotica (1994)', 'Extreme Measures (1996)', 'Eye for an Eye (1996)', \"Eye of Vichy, The (Oeil de Vichy, L') (1993)\", 'Face/Off (1997)', 'Faces (1968)', 'Fair Game (1995)', 'FairyTale: A True Story (1997)', 'Faithful (1996)', 'Fall (1997)', 'Fallen (1998)', 'Falling in Love Again (1980)', 'Family Thing, A (1996)', 'Fan, The (1996)', 'Fantasia (1940)', 'Far From Home: The Adventures of Yellow Dog (1995)', 'Farewell My Concubine (1993)', 'Farewell to Arms, A (1932)', 'Fargo (1996)', 'Farinelli: il castrato (1994)', 'Farmer & Chase (1995)', 'Fast, Cheap & Out of Control (1997)', 'Faster Pussycat! Kill! Kill! (1965)', 'Fatal Instinct (1993)', 'Father of the Bride (1950)', 'Father of the Bride Part II (1995)', \"Fathers' Day (1997)\", 'Faust (1994)', 'Fausto (1993)', 'Favor, The (1994)', 'Fear (1996)', 'Fear of a Black Hat (1993)', 'Fear, The (1995)', 'Fearless (1993)', 'Feast of July (1995)', 'Feeling Minnesota (1996)', 'Female Perversions (1996)', 'Field of Dreams (1989)', 'Fierce Creatures (1997)', 'Fifth Element, The (1997)', 'Fille seule, La (A Single Girl) (1995)', 'Fire Down Below (1997)', 'Fire on the Mountain (1996)', 'Firestorm (1998)', 'Firm, The (1993)', 'First Kid (1996)', 'First Knight (1995)', 'First Wives Club, The (1996)', 'Fish Called Wanda, A (1988)', 'Fled (1996)', 'Flesh and Bone (1993)', 'Flintstones, The (1994)', 'Flipper (1996)', 'Flirt (1995)', 'Flirting With Disaster (1996)', 'Flower of My Secret, The (Flor de mi secreto, La) (1995)', 'Flubber (1997)', 'Fluke (1995)', 'Fly Away Home (1996)', 'Fog, The (1980)', 'Fools Rush In (1997)', 'For Ever Mozart (1996)', 'For Love or Money (1993)', 'For Richer or Poorer (1997)', 'For Whom the Bell Tolls (1943)', 'For the Moment (1994)', 'Forbidden Christ, The (Cristo proibito, Il) (1950)', 'Forbidden Planet (1956)', 'Foreign Correspondent (1940)', 'Foreign Student (1994)', 'Forget Paris (1995)', 'Forrest Gump (1994)', 'Four Days in September (1997)', 'Four Rooms (1995)', 'Four Weddings and a Funeral (1994)', 'Fox and the Hound, The (1981)', 'Foxfire (1996)', 'Frankie Starlight (1995)', 'Free Willy (1993)', 'Free Willy 2: The Adventure Home (1995)', 'Free Willy 3: The Rescue (1997)', 'Freeway (1996)', 'French Kiss (1995)', 'French Twist (Gazon maudit) (1995)', 'Fresh (1994)', 'Friday (1995)', 'Fried Green Tomatoes (1991)', 'Frighteners, The (1996)', 'Frisk (1995)', 'From Dusk Till Dawn (1996)', 'Fugitive, The (1993)', 'Full Metal Jacket (1987)', 'Full Monty, The (1997)', 'Full Speed (1996)', 'Funeral, The (1996)', 'Funny Face (1957)', 'Further Gesture, A (1996)', 'G.I. Jane (1997)', 'Gabbeh (1996)', 'Game, The (1997)', 'Gandhi (1982)', 'Gang Related (1997)', 'Garden of Finzi-Contini, The (Giardino dei Finzi-Contini, Il) (1970)', 'Gaslight (1944)', 'Gate of Heavenly Peace, The (1995)', 'Gattaca (1997)', 'Gay Divorcee, The (1934)', 'George of the Jungle (1997)', 'Georgia (1995)', 'Germinal (1993)', 'Geronimo: An American Legend (1993)', 'Get Shorty (1995)', 'Get on the Bus (1996)', 'Getaway, The (1994)', 'Getting Away With Murder (1996)', 'Getting Even with Dad (1994)', 'Ghost (1990)', 'Ghost and Mrs. Muir, The (1947)', 'Ghost and the Darkness, The (1996)', 'Ghost in the Shell (Kokaku kidotai) (1995)', 'Ghosts of Mississippi (1996)', 'Giant (1956)', 'Gigi (1958)', \"Gilligan's Island: The Movie (1998)\", 'Girl 6 (1996)', 'Girl in the Cadillac (1995)', 'Girls Town (1996)', 'Glass Shield, The (1994)', 'Glengarry Glen Ross (1992)', 'Glimmer Man, The (1996)', 'Glory (1989)', 'Go Fish (1994)', 'Godfather, The (1972)', 'Godfather: Part II, The (1974)', 'Gold Diggers: The Secret of Bear Mountain (1995)', 'Golden Earrings (1947)', 'GoldenEye (1995)', \"Gone Fishin' (1997)\", 'Gone with the Wind (1939)', 'Good Man in Africa, A (1994)', 'Good Morning (1971)', 'Good Will Hunting (1997)', 'Good, The Bad and The Ugly, The (1966)', 'GoodFellas (1990)', 'Goofy Movie, A (1995)', 'Gordy (1995)', 'Grace of My Heart (1996)', 'Graduate, The (1967)', 'Grand Day Out, A (1992)', 'Grass Harp, The (1995)', 'Grateful Dead (1995)', 'Grease (1978)', 'Grease 2 (1982)', 'Great Day in Harlem, A (1994)', 'Great Dictator, The (1940)', 'Great Escape, The (1963)', 'Great Expectations (1998)', 'Great Race, The (1965)', 'Great White Hype, The (1996)', \"Gridlock'd (1997)\", 'Grifters, The (1990)', 'Grosse Fatigue (1994)', 'Grosse Pointe Blank (1997)', 'Groundhog Day (1993)', 'Grumpier Old Men (1995)', 'Guantanamera (1994)', 'Guilty as Sin (1993)', 'Gumby: The Movie (1995)', 'Hackers (1995)', 'Half Baked (1998)', 'Halloween: The Curse of Michael Myers (1995)', 'Hamlet (1996)', 'Hana-bi (1997)', 'Happy Gilmore (1996)', 'Hard Eight (1996)', 'Hard Rain (1998)', 'Hard Target (1993)', 'Harlem (1993)', 'Harold and Maude (1971)', 'Harriet the Spy (1996)', 'Hate (Haine, La) (1995)', 'Haunted World of Edward D. Wood Jr., The (1995)', 'He Walked by Night (1948)', 'Head Above Water (1996)', 'Hear My Song (1991)', 'Hearts and Minds (1996)', 'Heat (1995)', 'Heathers (1989)', 'Heaven & Earth (1993)', \"Heaven's Prisoners (1996)\", 'Heavenly Creatures (1994)', 'Heavy (1995)', 'Heavy Metal (1981)', 'Heavyweights (1994)', 'Hedd Wyn (1992)', 'Heidi Fleiss: Hollywood Madam (1995) ', 'Hellraiser: Bloodline (1996)', 'Henry V (1989)', 'Herbie Rides Again (1974)', 'Hercules (1997)', 'Here Comes Cookie (1935)', 'Hideaway (1995)', 'High Noon (1952)', 'High School High (1996)', 'Higher Learning (1995)', 'Highlander (1986)', 'Highlander III: The Sorcerer (1994)', 'His Girl Friday (1940)', 'Hollow Reed (1996)', 'Homage (1995)', 'Home Alone (1990)', 'Home Alone 3 (1997)', 'Home for the Holidays (1995)', 'Homeward Bound II: Lost in San Francisco (1996)', 'Homeward Bound: The Incredible Journey (1993)', 'Hoodlum (1997)', 'Hoop Dreams (1994)', 'Horse Whisperer, The (1998)', 'Horseman on the Roof, The (Hussard sur le toit, Le) (1995)', 'Hostile Intentions (1994)', 'Hot Shots! Part Deux (1993)', 'Hotel de Love (1996)', 'Hour of the Pig, The (1993)', 'House Arrest (1996)', 'House Party 3 (1994)', 'House of Yes, The (1997)', 'House of the Spirits, The (1993)', 'Houseguest (1994)', 'How to Be a Player (1997)', 'How to Make an American Quilt (1995)', 'Howling, The (1981)', 'Hudsucker Proxy, The (1994)', 'Hugo Pool (1997)', 'Hunchback of Notre Dame, The (1996)', 'Hungarian Fairy Tale, A (1987)', 'Hunt for Red October, The (1990)', 'Hunted, The (1995)', 'Hurricane Streets (1998)', 'Hush (1998)', \"I Can't Sleep (J'ai pas sommeil) (1994)\", \"I Don't Want to Talk About It (De eso no se habla) (1993)\", 'I Know What You Did Last Summer (1997)', 'I Like It Like That (1994)', 'I Love Trouble (1994)', 'I Shot Andy Warhol (1996)', \"I'll Do Anything (1994)\", \"I'm Not Rappaport (1996)\", 'I, Worst of All (Yo, la peor de todas) (1990)', 'I.Q. (1994)', 'Ice Storm, The (1997)', 'If Lucy Fell (1996)', 'Ill Gotten Gains (1997)', 'Immortal Beloved (1994)', 'In & Out (1997)', 'In Love and War (1996)', 'In the Army Now (1994)', 'In the Bleak Midwinter (1995)', 'In the Company of Men (1997)', 'In the Line of Duty 2 (1987)', 'In the Line of Fire (1993)', 'In the Mouth of Madness (1995)', 'In the Name of the Father (1993)', 'In the Realm of the Senses (Ai no corrida) (1976)', 'Incognito (1997)', 'Independence Day (ID4) (1996)', 'Indian Summer (1996)', 'Indian in the Cupboard, The (1995)', 'Indiana Jones and the Last Crusade (1989)', 'Infinity (1996)', 'Inkwell, The (1994)', 'Innocent Sleep, The (1995)', 'Innocents, The (1961)', 'Inspector General, The (1949)', 'Interview with the Vampire (1994)', 'Intimate Relations (1996)', 'Inventing the Abbotts (1997)', 'Invitation, The (Zaproszenie) (1986)', 'Island of Dr. Moreau, The (1996)', 'It Could Happen to You (1994)', 'It Happened One Night (1934)', 'It Takes Two (1995)', \"It's My Party (1995)\", \"It's a Wonderful Life (1946)\", 'JLG/JLG - autoportrait de décembre (1994)', 'Jack (1996)', 'Jack and Sarah (1995)', 'Jackal, The (1997)', 'Jackie Brown (1997)', \"Jackie Chan's First Strike (1996)\", 'Jade (1995)', 'James and the Giant Peach (1996)', 'Jane Eyre (1996)', \"Jason's Lyric (1994)\", 'Jaws (1975)', 'Jaws 2 (1978)', 'Jaws 3-D (1983)', 'Jean de Florette (1986)', 'Jefferson in Paris (1995)', 'Jeffrey (1995)', 'Jerky Boys, The (1994)', 'Jerry Maguire (1996)', 'Jimmy Hollywood (1994)', 'Jingle All the Way (1996)', \"Joe's Apartment (1996)\", 'Johnny 100 Pesos (1993)', 'Johnny Mnemonic (1995)', 'Johns (1996)', 'Journey of August King, The (1995)', 'Joy Luck Club, The (1993)', 'Jude (1996)', 'Judge Dredd (1995)', 'Judgment Night (1993)', 'Jumanji (1995)', 'Jungle Book, The (1994)', 'Jungle2Jungle (1997)', 'Junior (1994)', \"Jupiter's Wife (1994)\", 'Jurassic Park (1993)', 'Juror, The (1996)', 'Jury Duty (1995)', 'Just Cause (1995)', 'Kalifornia (1993)', 'Kama Sutra: A Tale of Love (1996)', 'Kansas City (1996)', 'Kaspar Hauser (1993)', 'Kazaam (1996)', 'Keys to Tulsa (1997)', 'Kicked in the Head (1997)', 'Kicking and Screaming (1995)', \"Kid in King Arthur's Court, A (1995)\", 'Kids (1995)', 'Kids in the Hall: Brain Candy (1996)', 'Kika (1993)', 'Killer (Bulletproof Heart) (1994)', 'Killer: A Journal of Murder (1995)', 'Killing Fields, The (1984)', 'Killing Zoe (1994)', 'Kim (1950)', 'King of New York (1990)', 'King of the Hill (1993)', 'Kingpin (1996)', 'Kiss Me, Guido (1997)', 'Kiss of Death (1995)', 'Kiss the Girls (1997)', 'Kissed (1996)', 'Kolya (1996)', 'Koyaanisqatsi (1983)', 'Kull the Conqueror (1997)', 'Kundun (1997)', 'L.A. Confidential (1997)', 'Lady of Burlesque (1943)', 'Ladybird Ladybird (1994)', 'Lamerica (1994)', 'Land Before Time III: The Time of the Great Giving (1995) (V)', 'Land and Freedom (Tierra y libertad) (1995)', 'Larger Than Life (1996)', 'Lashou shentan (1992)', 'Lassie (1994)', 'Last Action Hero (1993)', 'Last Dance (1996)', 'Last Klezmer: Leopold Kozlowski, His Life and Music, The (1995)', 'Last Man Standing (1996)', 'Last Summer in the Hamptons (1995)', 'Last Supper, The (1995)', 'Last Time I Committed Suicide, The (1997)', 'Last Time I Saw Paris, The (1954)', 'Last of the Mohicans, The (1992)', 'Late Bloomers (1996)', 'Laura (1944)', 'Lawnmower Man 2: Beyond Cyberspace (1996)', 'Lawnmower Man, The (1992)', 'Lawrence of Arabia (1962)', 'Lay of the Land, The (1997)', 'Leading Man, The (1996)', 'Leave It to Beaver (1997)', 'Leaving Las Vegas (1995)', 'Legal Deceit (1997)', 'Legends of the Fall (1994)', 'Leopard Son, The (1996)', 'Letter From Death Row, A (1998)', 'Liar Liar (1997)', 'Liebelei (1933)', 'Life Less Ordinary, A (1997)', 'Life with Mikey (1993)', 'Lightning Jack (1994)', 'Like Water For Chocolate (Como agua para chocolate) (1992)', 'Line King: Al Hirschfeld, The (1996)', 'Lion King, The (1994)', 'Little Big League (1994)', 'Little Buddha (1993)', 'Little City (1998)', 'Little Lord Fauntleroy (1936)', 'Little Odessa (1994)', 'Little Princess, A (1995)', 'Little Princess, The (1939)', 'Little Rascals, The (1994)', 'Little Women (1994)', 'Live Nude Girls (1995)', 'Living in Oblivion (1995)', 'Loaded (1994)', 'Local Hero (1983)', 'Loch Ness (1995)', 'Locusts, The (1997)', 'Lone Star (1996)', 'Long Kiss Goodnight, The (1996)', 'Looking for Richard (1996)', 'Lord of Illusions (1995)', 'Losing Chase (1996)', 'Losing Isaiah (1995)', 'Lost Highway (1997)', 'Lost Horizon (1937)', 'Lost World: Jurassic Park, The (1997)', 'Lost in Space (1998)', 'Lotto Land (1995)', 'Love & Human Remains (1993)', 'Love Affair (1994)', 'Love Bug, The (1969)', 'Love Is All There Is (1996)', 'Love Jones (1997)', 'Love Serenade (1996)', 'Love and Death on Long Island (1997)', 'Love and Other Catastrophes (1996)', 'Love and a .45 (1994)', 'Love in the Afternoon (1957)', 'Love! Valour! Compassion! (1997)', \"Lover's Knot (1996)\", 'Low Down Dirty Shame, A (1994)', 'Low Life, The (1994)', 'M (1931)', 'M*A*S*H (1970)', 'M. Butterfly (1993)', 'MURDER and murder (1996)', 'Ma vie en rose (My Life in Pink) (1997)', 'Machine, The (1994)', 'Mad City (1997)', 'Mad Dog Time (1996)', 'Mad Love (1995)', 'Madame Butterfly (1995)', 'Made in America (1993)', 'Madness of King George, The (1994)', 'Madonna: Truth or Dare (1991)', 'Magic Hour, The (1998)', 'Magnificent Seven, The (1954)', 'Major Payne (1994)', 'Malice (1993)', 'Mallrats (1995)', 'Maltese Falcon, The (1941)', 'Mamma Roma (1962)', 'Man Who Knew Too Little, The (1997)', 'Man Who Would Be King, The (1975)', 'Man Without a Face, The (1993)', 'Man from Down Under, The (1943)', 'Man in the Iron Mask, The (1998)', 'Man of No Importance, A (1994)', 'Man of the House (1995)', 'Man of the Year (1995)', 'Manchurian Candidate, The (1962)', 'Manhattan (1979)', 'Manhattan Murder Mystery (1993)', 'Manny & Lo (1996)', 'Manon of the Spring (Manon des sources) (1986)', \"Margaret's Museum (1995)\", 'Mark of Zorro, The (1940)', 'Marked for Death (1990)', 'Marlene Dietrich: Shadow and Light (1996) ', 'Mars Attacks! (1996)', \"Marvin's Room (1996)\", 'Mary Poppins (1964)', 'Mary Reilly (1996)', \"Mary Shelley's Frankenstein (1994)\", 'Mask, The (1994)', \"Mat' i syn (1997)\", 'MatchMaker, The (1997)', 'Matilda (1996)', 'Maverick (1994)', 'Maximum Risk (1996)', 'Maya Lin: A Strong Clear Vision (1994)', 'Maybe, Maybe Not (Bewegte Mann, Der) (1994)', \"McHale's Navy (1997)\", 'Mediterraneo (1991)', 'Meet John Doe (1941)', 'Meet Me in St. Louis (1944)', 'Meet Wally Sparks (1997)', 'Men With Guns (1997)', 'Men in Black (1997)', 'Men of Means (1998)', 'Menace II Society (1993)', 'Mercury Rising (1998)', 'Metisse (Café au Lait) (1993)', 'Metro (1997)', 'Miami Rhapsody (1995)', 'Michael (1996)', 'Michael Collins (1996)', \"Microcosmos: Le peuple de l'herbe (1996)\", 'Midnight Dancers (Sibak) (1994)', 'Midnight in the Garden of Good and Evil (1997)', 'Mighty Aphrodite (1995)', 'Mighty Morphin Power Rangers: The Movie (1995)', 'Mighty, The (1998)', 'Milk Money (1994)', 'Mille bolle blu (1993)', \"Miller's Crossing (1990)\", 'Mimic (1997)', 'Mina Tannenbaum (1994)', 'Miracle on 34th Street (1994)', 'Mirage (1995)', 'Mirror Has Two Faces, The (1996)', 'Mission: Impossible (1996)', 'Misérables, Les (1995)', 'Mixed Nuts (1994)', 'Modern Affair, A (1995)', 'Moll Flanders (1996)', 'Mondo (1996)', 'Money Talks (1997)', 'Money Train (1995)', 'Month by the Lake, A (1995)', 'Monty Python and the Holy Grail (1974)', \"Monty Python's Life of Brian (1979)\", 'Moonlight and Valentino (1995)', 'Mortal Kombat (1995)', 'Mortal Kombat: Annihilation (1997)', 'Mostro, Il (1994)', 'Mother (1996)', 'Mother Night (1996)', 'Mouse Hunt (1997)', \"Mr. Holland's Opus (1995)\", 'Mr. Jones (1993)', 'Mr. Magoo (1997)', 'Mr. Smith Goes to Washington (1939)', 'Mr. Wonderful (1993)', 'Mr. Wrong (1996)', 'Mrs. Brown (Her Majesty, Mrs. Brown) (1997)', 'Mrs. Dalloway (1997)', 'Mrs. Doubtfire (1993)', 'Mrs. Parker and the Vicious Circle (1994)', 'Mrs. Winterbourne (1996)', 'Much Ado About Nothing (1993)', 'Mulholland Falls (1996)', 'Multiplicity (1996)', 'Muppet Treasure Island (1996)', 'Murder at 1600 (1997)', 'Murder in the First (1995)', 'Murder, My Sweet (1944)', \"Muriel's Wedding (1994)\", 'Mute Witness (1994)', \"My Best Friend's Wedding (1997)\", 'My Crazy Life (Mi vida loca) (1993)', 'My Fair Lady (1964)', 'My Family (1995)', 'My Favorite Season (1993)', 'My Favorite Year (1982)', 'My Fellow Americans (1996)', 'My Left Foot (1989)', \"My Life and Times With Antonin Artaud (En compagnie d'Antonin Artaud) (1993)\", 'My Life as a Dog (Mitt liv som hund) (1985)', 'My Man Godfrey (1936)', 'My Own Private Idaho (1991)', 'Mystery Science Theater 3000: The Movie (1996)', 'Nadja (1994)', 'Naked (1993)', 'Naked Gun 33 1/3: The Final Insult (1994)', 'Naked in New York (1994)', \"National Lampoon's Senior Trip (1995)\", 'Natural Born Killers (1994)', 'Nell (1994)', 'Nelly & Monsieur Arnaud (1995)', 'Nemesis 2: Nebula (1995)', 'Neon Bible, The (1995)', 'Net, The (1995)', 'NeverEnding Story III, The (1994)', 'New Age, The (1994)', 'New Jersey Drive (1995)', 'New York Cop (1996)', 'Newton Boys, The (1998)', 'Next Karate Kid, The (1994)', 'Next Step, The (1995)', 'Niagara, Niagara (1997)', 'Nick of Time (1995)', 'Nico Icon (1995)', 'Night Falls on Manhattan (1997)', 'Night Flier (1997)', 'Night of the Living Dead (1968)', 'Night on Earth (1991)', 'Nightmare Before Christmas, The (1993)', 'Nightmare on Elm Street, A (1984)', 'Nightwatch (1997)', 'Nikita (La Femme Nikita) (1990)', 'Nil By Mouth (1997)', 'Nina Takes a Lover (1994)', 'Nine Months (1995)', 'Ninotchka (1939)', 'Nixon (1995)', 'No Escape (1994)', 'Nobody Loves Me (Keiner liebt mich) (1994)', \"Nobody's Fool (1994)\", 'Normal Life (1996)', 'North (1994)', 'North by Northwest (1959)', 'Nosferatu (Nosferatu, eine Symphonie des Grauens) (1922)', 'Nosferatu a Venezia (1986)', 'Nothing Personal (1995)', 'Nothing to Lose (1994)', 'Notorious (1946)', 'Now and Then (1995)', 'Nowhere (1997)', 'Nutty Professor, The (1996)', 'Nénette et Boni (1996)', 'Object of My Affection, The (1998)', 'Of Human Bondage (1934)', 'Of Love and Shadows (1994)', 'Office Killer (1997)', 'Old Lady Who Walked in the Sea, The (Vieille qui marchait dans la mer, La) (1991)', 'Old Man and the Sea, The (1958)', 'Old Yeller (1957)', 'Oliver & Company (1988)', 'Omen, The (1976)', 'On Golden Pond (1981)', 'Once Upon a Time in America (1984)', 'Once Upon a Time in the West (1969)', 'Once Upon a Time... When We Were Colored (1995)', 'Once Were Warriors (1994)', 'One Fine Day (1996)', \"One Flew Over the Cuckoo's Nest (1975)\", 'One Night Stand (1997)', 'Only You (1994)', 'Open Season (1996)', 'Operation Dumbo Drop (1995)', 'Original Gangstas (1996)', 'Orlando (1993)', 'Oscar & Lucinda (1997)', 'Othello (1995)', 'Other Voices, Other Rooms (1997)', 'Out to Sea (1997)', 'Outbreak (1995)', 'Outlaw, The (1943)', 'Pagemaster, The (1994)', 'Pallbearer, The (1996)', 'Palmetto (1998)', 'Palookaville (1996)', 'Panther (1995)', 'Paper, The (1994)', 'Paradise Lost: The Child Murders at Robin Hood Hills (1996)', 'Paradise Road (1997)', 'Parent Trap, The (1961)', 'Paris Is Burning (1990)', 'Paris Was a Woman (1995)', 'Paris, France (1993)', 'Paris, Texas (1984)', 'Party Girl (1995)', 'Passion Fish (1992)', 'Pather Panchali (1955)', 'Paths of Glory (1957)', 'Patton (1970)', 'Peacemaker, The (1997)', 'Penny Serenade (1941)', 'People vs. Larry Flynt, The (1996)', 'Perez Family, The (1995)', 'Perfect Candidate, A (1996)', 'Perfect World, A (1993)', 'Persuasion (1995)', 'Pest, The (1997)', \"Pete's Dragon (1977)\", 'Phantom, The (1996)', 'Phantoms (1998)', \"Pharaoh's Army (1995)\", 'Phat Beach (1996)', 'Phenomenon (1996)', 'Philadelphia (1993)', 'Philadelphia Story, The (1940)', 'Piano, The (1993)', 'Picnic (1955)', 'Picture Bride (1995)', 'Picture Perfect (1997)', 'Pie in the Sky (1995)', 'Pillow Book, The (1995)', 'Pink Floyd - The Wall (1982)', 'Pinocchio (1940)', 'Platoon (1986)', 'Playing God (1997)', 'Pocahontas (1995)', 'Poetic Justice (1993)', 'Poison Ivy II (1995)', 'Police Story 4: Project S (Chao ji ji hua) (1993)', 'Pollyanna (1960)', 'Pompatus of Love, The (1996)', 'Ponette (1996)', 'Portrait of a Lady, The (1996)', 'Postino, Il (1994)', 'Postman, The (1997)', 'Powder (1995)', 'Power 98 (1995)', \"Preacher's Wife, The (1996)\", 'Prefontaine (1997)', 'Pretty Woman (1990)', 'Price Above Rubies, A (1998)', 'Priest (1994)', 'Primal Fear (1996)', 'Primary Colors (1998)', 'Princess Bride, The (1987)', 'Princess Caraboo (1994)', 'Prisoner of the Mountains (Kavkazsky Plennik) (1996)', 'Private Benjamin (1980)', 'Private Parts (1997)', 'Professional, The (1994)', 'Program, The (1993)', 'Promesse, La (1996)', 'Promise, The (Versprechen, Das) (1994)', 'Prophecy II, The (1998)', 'Prophecy, The (1995)', 'Psycho (1960)', 'Pulp Fiction (1994)', 'Pump Up the Volume (1990)', 'Purple Noon (1960)', 'Pushing Hands (1992)', \"Pyromaniac's Love Story, A (1995)\", 'Quartier Mozart (1992)', 'Queen Margot (Reine Margot, La) (1994)', 'Quest, The (1996)', 'Quick and the Dead, The (1995)', 'Quiet Man, The (1952)', 'Quiet Room, The (1996)', 'Quiz Show (1994)', 'Race the Sun (1996)', 'Radioland Murders (1994)', 'Raging Bull (1980)', 'Raiders of the Lost Ark (1981)', 'Rainmaker, The (1997)', 'Raise the Red Lantern (1991)', 'Raising Arizona (1987)', 'Ran (1985)', 'Ransom (1996)', 'Raw Deal (1948)', 'Ready to Wear (Pret-A-Porter) (1994)', 'Real Genius (1985)', 'Reality Bites (1994)', 'Rear Window (1954)', 'Rebecca (1940)', 'Rebel Without a Cause (1955)', 'Reckless (1995)', 'Red Corner (1997)', 'Red Firecracker, Green Firecracker (1994)', 'Red Rock West (1992)', 'Ref, The (1994)', 'Relative Fear (1994)', 'Relic, The (1997)', 'Reluctant Debutante, The (1958)', 'Remains of the Day, The (1993)', 'Renaissance Man (1994)', 'Rendezvous in Paris (Rendez-vous de Paris, Les) (1995)', 'Rent-a-Kid (1995)', 'Replacement Killers, The (1998)', 'Reservoir Dogs (1992)', 'Restoration (1995)', 'Return of Martin Guerre, The (Retour de Martin Guerre, Le) (1982)', 'Return of the Jedi (1983)', 'Return of the Pink Panther, The (1974)', 'Rhyme & Reason (1997)', \"Rich Man's Wife, The (1996)\", 'Richard III (1995)', 'Richie Rich (1994)', 'Ridicule (1996)', 'Right Stuff, The (1983)', 'Ripe (1996)', 'Rising Sun (1993)', 'River Wild, The (1994)', 'Road to Wellville, The (1994)', 'Rob Roy (1995)', \"Robert A. Heinlein's The Puppet Masters (1994)\", 'Robin Hood: Men in Tights (1993)', 'Robin Hood: Prince of Thieves (1991)', 'Robocop 3 (1993)', 'Rock, The (1996)', 'Rocket Man (1997)', 'Roman Holiday (1953)', 'Romeo Is Bleeding (1993)', 'Romper Stomper (1992)', \"Romy and Michele's High School Reunion (1997)\", 'Room with a View, A (1986)', 'Roommates (1995)', \"Roseanna's Grave (For Roseanna) (1997)\", 'Rosencrantz and Guildenstern Are Dead (1990)', 'Rosewood (1997)', 'Rough Magic (1995)', 'Ruby in Paradise (1993)', 'Rudy (1993)', 'Ruling Class, The (1972)', 'Rumble in the Bronx (1995)', 'Run of the Country, The (1995)', 'S.F.W. (1994)', 'Sabrina (1954)', 'Sabrina (1995)', 'Safe (1995)', 'Safe Passage (1994)', 'Saint of Fort Washington, The (1993)', 'Saint, The (1997)', 'Salut cousin! (1996)', 'Santa Clause, The (1994)', 'Santa with Muscles (1996)', 'Savage Nights (Nuits fauves, Les) (1992)', 'Scarlet Letter, The (1926)', 'Scarlet Letter, The (1995)', \"Schindler's List (1993)\", 'Schizopolis (1996)', 'Scout, The (1994)', 'Scream (1996)', 'Scream 2 (1997)', 'Scream of Stone (Schrei aus Stein) (1991)', 'Screamers (1995)', 'Search for One-eye Jimmy, The (1996)', 'Searching for Bobby Fischer (1993)', 'Second Jungle Book: Mowgli & Baloo, The (1997)', 'Secret Adventures of Tom Thumb, The (1993)', 'Secret Agent, The (1996)', 'Secret Garden, The (1993)', 'Secret of Roan Inish, The (1994)', 'Secrets & Lies (1996)', 'Selena (1997)', 'Sense and Sensibility (1995)', 'Senseless (1998)', 'Serial Mom (1994)', 'Set It Off (1996)', 'Seven (Se7en) (1995)', 'Seven Years in Tibet (1997)', 'Seventh Seal, The (Sjunde inseglet, Det) (1957)', 'Sex, Lies, and Videotape (1989)', 'Sexual Life of the Belgians, The (1994)', 'Sgt. Bilko (1996)', 'Shadow Conspiracy (1997)', 'Shadow of Angels (Schatten der Engel) (1976)', 'Shadow, The (1994)', 'Shadowlands (1993)', 'Shadows (Cienie) (1988)', 'Shaggy Dog, The (1959)', 'Shall We Dance? (1937)', 'Shall We Dance? (1996)', 'Shallow Grave (1994)', 'Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)', 'Shawshank Redemption, The (1994)', \"She's So Lovely (1997)\", \"She's the One (1996)\", 'Shiloh (1997)', 'Shine (1996)', 'Shining, The (1980)', 'Shooter, The (1995)', 'Shooting Fish (1997)', 'Shopping (1994)', 'Short Cuts (1993)', 'Show, The (1995)', 'Showgirls (1995)', 'Silence of the Lambs, The (1991)', 'Silence of the Palace, The (Saimt el Qusur) (1994)', 'Simple Twist of Fate, A (1994)', 'Simple Wish, A (1997)', \"Singin' in the Rain (1952)\", 'Sirens (1994)', 'Six Degrees of Separation (1993)', 'Sixth Man, The (1997)', 'Sleeper (1973)', 'Sleepers (1996)', 'Sleepless in Seattle (1993)', 'Sleepover (1995)', 'Sliding Doors (1998)', 'Sling Blade (1996)', 'Slingshot, The (1993)', 'Sliver (1993)', 'Small Faces (1995)', 'Smile Like Yours, A (1997)', \"Smilla's Sense of Snow (1997)\", 'Smoke (1995)', 'Sneakers (1992)', 'Snow White and the Seven Dwarfs (1937)', 'So Dear to My Heart (1949)', 'So I Married an Axe Murderer (1993)', 'Solo (1996)', 'Some Folks Call It a Sling Blade (1993)', 'Some Kind of Wonderful (1987)', 'Some Like It Hot (1959)', \"Some Mother's Son (1996)\", 'Somebody to Love (1994)', \"Someone Else's America (1995)\", 'Something to Talk About (1995)', 'Somewhere in Time (1980)', 'Son in Law (1993)', \"Sophie's Choice (1982)\", 'Soul Food (1997)', 'Sound of Music, The (1965)', 'Space Jam (1996)', 'Spanish Prisoner, The (1997)', 'Spanking the Monkey (1994)', 'Spawn (1997)', 'Specialist, The (1994)', 'Species (1995)', 'Speechless (1994)', 'Speed (1994)', 'Speed 2: Cruise Control (1997)', 'Spellbound (1945)', 'Sphere (1998)', 'Spice World (1997)', 'Spirits of the Dead (Tre passi nel delirio) (1968)', 'Spitfire Grill, The (1996)', 'Sprung (1997)', 'Spy Hard (1996)', 'Squeeze (1996)', 'Stag (1997)', 'Stalingrad (1993)', 'Stalker (1979)', 'Stand by Me (1986)', 'Star Kid (1997)', \"Star Maker, The (Uomo delle stelle, L') (1995)\", 'Star Maps (1997)', 'Star Trek III: The Search for Spock (1984)', 'Star Trek IV: The Voyage Home (1986)', 'Star Trek V: The Final Frontier (1989)', 'Star Trek VI: The Undiscovered Country (1991)', 'Star Trek: First Contact (1996)', 'Star Trek: Generations (1994)', 'Star Trek: The Motion Picture (1979)', 'Star Trek: The Wrath of Khan (1982)', 'Star Wars (1977)', 'Stargate (1994)', 'Stars Fell on Henrietta, The (1995)', 'Starship Troopers (1997)', 'Steal Big, Steal Little (1995)', 'Stealing Beauty (1996)', 'Steel (1997)', 'Stefano Quantestorie (1993)', \"Stephen King's The Langoliers (1995)\", 'Sting, The (1973)', 'Stonewall (1995)', 'Story of Xinghua, The (1993)', 'Strange Days (1995)', 'Stranger in the House (1997)', 'Stranger, The (1994)', 'Strawberry and Chocolate (Fresa y chocolate) (1993)', 'Street Fighter (1994)', 'Streetcar Named Desire, A (1951)', 'Strictly Ballroom (1992)', 'Striking Distance (1993)', 'Stripes (1981)', 'Striptease (1996)', 'Stuart Saves His Family (1995)', 'Stupids, The (1996)', 'SubUrbia (1997)', 'Substance of Fire, The (1996)', 'Substitute, The (1996)', 'Sudden Death (1995)', 'Sudden Manhattan (1996)', 'Sum of Us, The (1994)', 'Sunchaser, The (1996)', 'Sunset Blvd. (1950)', 'Sunset Park (1996)', 'Super Mario Bros. (1993)', 'Supercop (1992)', 'Surviving Picasso (1996)', 'Surviving the Game (1994)', 'Suture (1993)', 'Swan Princess, The (1994)', 'Sweet Hereafter, The (1997)', 'Sweet Nothing (1995)', 'Swept from the Sea (1997)', 'Swimming with Sharks (1995)', 'Swingers (1996)', 'Swiss Family Robinson (1960)', 'Switchback (1997)', 'Switchblade Sisters (1975)', 'Sword in the Stone, The (1963)', 'Symphonie pastorale, La (1946)', 'T-Men (1947)', 'Tainted (1998)', 'Tales From the Crypt Presents: Demon Knight (1995)', 'Tales from the Crypt Presents: Bordello of Blood (1996)', 'Tales from the Hood (1995)', 'Talking About Sex (1994)', 'Tango Lesson, The (1997)', 'Tank Girl (1995)', 'Target (1995)', 'Taxi Driver (1976)', 'Telling Lies in America (1997)', 'Temptress Moon (Feng Yue) (1996)', 'Terminal Velocity (1994)', 'Terminator 2: Judgment Day (1991)', 'Terminator, The (1984)', 'Terror in a Texas Town (1958)', 'Tetsuo II: Body Hammer (1992)', 'That Darn Cat! (1965)', 'That Darn Cat! (1997)', 'That Old Feeling (1997)', 'That Thing You Do! (1996)', 'The Courtyard (1995)', 'The Deadly Cure (1996)', 'The Innocent (1994)', 'Theodore Rex (1995)', 'They Made Me a Criminal (1939)', 'Thieves (Voleurs, Les) (1996)', 'Thin Blue Line, The (1988)', 'Thin Line Between Love and Hate, A (1996)', 'Thin Man, The (1934)', \"Things to Do in Denver when You're Dead (1995)\", 'Thinner (1996)', 'Third Man, The (1949)', 'Thirty-Two Short Films About Glenn Gould (1993)', 'This Is Spinal Tap (1984)', 'Thousand Acres, A (1997)', 'Three Caballeros, The (1945)', 'Three Colors: Blue (1993)', 'Three Colors: Red (1994)', 'Three Colors: White (1994)', 'Three Lives and Only One Death (1996)', 'Three Musketeers, The (1993)', 'Three Wishes (1995)', 'Threesome (1994)', 'Tie Me Up! Tie Me Down! (1990)', 'Tie That Binds, The (1995)', 'Tigrero: A Film That Was Never Made (1994)', 'Time Tracers (1995)', 'Time to Kill, A (1996)', 'Timecop (1994)', 'Tin Cup (1996)', 'Tin Drum, The (Blechtrommel, Die) (1979)', 'Tin Men (1987)', 'Titanic (1997)', 'To Be or Not to Be (1942)', 'To Catch a Thief (1955)', 'To Cross the Rubicon (1991)', 'To Die For (1995)', 'To Gillian on Her 37th Birthday (1996)', 'To Have, or Not (1995)', 'To Kill a Mockingbird (1962)', 'To Live (Huozhe) (1994)', 'To Wong Foo, Thanks for Everything! Julie Newmar (1995)', 'Tokyo Fist (1995)', 'Tom & Viv (1994)', 'Tom and Huck (1995)', 'Tombstone (1993)', 'Tommy Boy (1995)', 'Tomorrow Never Dies (1997)', 'Top Gun (1986)', 'Top Hat (1935)', 'Total Eclipse (1995)', 'Touch (1997)', 'Touch of Evil (1958)', 'Tough and Deadly (1995)', 'Touki Bouki (Journey of the Hyena) (1973)', 'Toy Story (1995)', 'Trainspotting (1996)', 'Transformers: The Movie, The (1986)', 'Traveller (1997)', 'Treasure of the Sierra Madre, The (1948)', 'Trees Lounge (1996)', 'Trial and Error (1997)', 'Trial by Jury (1994)', 'Trigger Effect, The (1996)', 'True Crime (1995)', 'True Lies (1994)', 'True Romance (1993)', 'Truman Show, The (1998)', 'Trust (1990)', 'Truth About Cats & Dogs, The (1996)', 'Truth or Consequences, N.M. (1997)', 'Turbo: A Power Rangers Movie (1997)', 'Turbulence (1997)', 'Turning, The (1992)', 'Twelfth Night (1996)', 'Twelve Monkeys (1995)', 'Twilight (1998)', 'Twin Town (1997)', 'Twisted (1996)', 'Twister (1996)', 'Two Bits (1995)', 'Two Deaths (1995)', 'Two Friends (1986) ', 'Two Much (1996)', 'Two if by Sea (1996)', 'Two or Three Things I Know About Her (1966)', 'U Turn (1997)', 'U.S. Marshalls (1998)', \"Ulee's Gold (1997)\", 'Umbrellas of Cherbourg, The (Parapluies de Cherbourg, Les) (1964)', 'Unbearable Lightness of Being, The (1988)', 'Under Siege (1992)', 'Under Siege 2: Dark Territory (1995)', 'Underground (1995)', 'Underneath, The (1995)', 'Underworld (1997)', 'Unforgettable (1996)', 'Unforgiven (1992)', 'Unhook the Stars (1996)', 'Unstrung Heroes (1995)', 'Until the End of the World (Bis ans Ende der Welt) (1991)', 'Unzipped (1995)', 'Up Close and Personal (1996)', 'Up in Smoke (1978)', 'Usual Suspects, The (1995)', 'Vampire in Brooklyn (1995)', 'Van, The (1996)', 'Vanya on 42nd Street (1994)', 'Vegas Vacation (1997)', 'Venice/Venice (1992)', 'Vermin (1998)', 'Vermont Is For Lovers (1992)', 'Vertigo (1958)', 'Very Brady Sequel, A (1996)', 'Very Natural Thing, A (1974)', 'Victor/Victoria (1982)', 'Vie est belle, La (Life is Rosey) (1987)', 'Village of the Damned (1995)', 'Virtuosity (1995)', 'Visitors, The (Visiteurs, Les) (1993)', 'Volcano (1997)', 'Wag the Dog (1997)', 'Waiting for Guffman (1996)', 'Waiting to Exhale (1995)', 'Walk in the Clouds, A (1995)', 'Walk in the Sun, A (1945)', 'Walkabout (1971)', 'Walking Dead, The (1995)', 'Walking and Talking (1996)', 'Wallace & Gromit: The Best of Aardman Animation (1996)', 'War Room, The (1993)', 'War at Home, The (1996)', 'War, The (1994)', 'Warriors of Virtue (1997)', 'Washington Square (1997)', 'Waterworld (1995)', 'Wedding Bell Blues (1996)', 'Wedding Gift, The (1994)', 'Wedding Singer, The (1998)', \"Weekend at Bernie's (1989)\", 'Welcome To Sarajevo (1997)', 'Welcome to the Dollhouse (1995)', \"Wend Kuuni (God's Gift) (1982)\", \"Wes Craven's New Nightmare (1994)\", 'What Happened Was... (1994)', \"What's Eating Gilbert Grape (1993)\", \"What's Love Got to Do with It (1993)\", 'When Harry Met Sally... (1989)', 'When Night Is Falling (1995)', 'When We Were Kings (1996)', 'When a Man Loves a Woman (1994)', 'When the Cats Away (Chacun cherche son chat) (1996)', 'While You Were Sleeping (1995)', 'White Balloon, The (1995)', \"White Man's Burden (1995)\", 'White Squall (1996)', 'Whole Wide World, The (1996)', \"Widows' Peak (1994)\", 'Wife, The (1995)', 'Wild America (1997)', 'Wild Bill (1995)', 'Wild Bunch, The (1969)', 'Wild Reeds (1994)', 'Wild Things (1998)', \"William Shakespeare's Romeo and Juliet (1996)\", 'Willy Wonka and the Chocolate Factory (1971)', 'Window to Paris (1994)', 'Wings of Courage (1995)', 'Wings of Desire (1987)', 'Wings of the Dove, The (1997)', 'Winnie the Pooh and the Blustery Day (1968)', 'Winter Guest, The (1997)', 'Wishmaster (1997)', 'With Honors (1994)', 'Withnail and I (1987)', 'Witness (1985)', 'Wizard of Oz, The (1939)', 'Wolf (1994)', 'Woman in Question, The (1950)', 'Women, The (1939)', 'Wonderful, Horrible Life of Leni Riefenstahl, The (1993)', 'Wonderland (1997)', \"Wooden Man's Bride, The (Wu Kui) (1994)\", 'World of Apu, The (Apur Sansar) (1959)', 'Wrong Trousers, The (1993)', 'Wyatt Earp (1994)', 'Yankee Zulu (1994)', 'Year of the Horse (1997)', 'You So Crazy (1994)', 'Young Frankenstein (1974)', 'Young Guns (1988)', 'Young Guns II (1990)', \"Young Poisoner's Handbook, The (1995)\", 'Zeus and Roxanne (1997)', 'unknown', 'Á köldum klaka (Cold Fever) (1994)']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users  = len(dls.classes['user'])\n",
    "n_movies = len(dls.classes['title'])\n",
    "n_factors = 5\n",
    "\n",
    "user_factors = torch.randn(n_users, n_factors)\n",
    "movie_factors = torch.randn(n_movies, n_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the result for a particular movie and user combination, we have to look up the index of the movie in our movie latent factor matrix and the index of the user in our user latent factor matrix; then we can do our dot product between the two latent factor vectors. But *look up in an index* is not an operation our deep learning models know how to do. They know how to do matrix products, and activation functions.\n",
    "\n",
    "Fortunately, it turns out that we can represent *look up in an index* as a matrix product. The trick is to replace our indices with one-hot-encoded vectors. Here is an example of what happens if we multiply a vector by a one-hot-encoded vector representing the index 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_3 = one_hot(3, n_users).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4586, -0.9915, -0.4052, -0.3621, -0.5908])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors.t() @ one_hot_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gives us the same vector as the one at index 3 in the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4586, -0.9915, -0.4052, -0.3621, -0.5908])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do that for a few indices at once, we will have a matrix of one-hot-encoded vectors, and that operation will be a matrix multiplication! This would be a perfectly acceptable way to build models using this kind of architecture, except that it would use a lot more memory and time than necessary. We know that there is no real underlying reason to store the one-hot-encoded vector, or to search through it to find the occurrence of the number one—we should just be able to index into an array directly with an integer. Therefore, most deep learning libraries, including PyTorch, include a special layer that does just this; it indexes into a vector using an integer, but has its derivative calculated in such a way that it is identical to what it would have been if it had done a matrix multiplication with a one-hot-encoded vector. This is called an *embedding*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> jargon: Embedding: Multiplying by a one-hot-encoded matrix, using the computational shortcut that it can be implemented by simply indexing directly. This is quite a fancy word for a very simple concept. The thing that you multiply the one-hot-encoded matrix by (or, using the computational shortcut, index into directly) is called the _embedding matrix_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computer vision, we have a very easy way to get all the information of a pixel through its RGB values: each pixel in a colored image is represented by three numbers. Those three numbers give us the redness, the greenness and the blueness, which is enough to get our model to work afterward.\n",
    "\n",
    "For the problem at hand, we don't have the same easy way to characterize a user or a movie. There are probably relations with genres: if a given user likes romance, they are likely to give higher scores to romance movies. Other factors might be whether the movie is more action-oriented versus heavy on dialogue, or the presence of a specific actor that a user might particularly like. \n",
    "\n",
    "How do we determine numbers to characterize those? The answer is, we don't. We will let our model *learn* them. By analyzing the existing relations between users and movies, our model can figure out itself the features that seem important or not.\n",
    "\n",
    "This is what embeddings are. We will attribute to each of our users and each of our movies a random vector of a certain length (here, `n_factors=5`), and we will make those learnable parameters. That means that at each step, when we compute the loss by comparing our predictions to our targets, we will compute the gradients of the loss with respect to those embedding vectors and update them with the rules of SGD (or another optimizer).\n",
    "\n",
    "At the beginning, those numbers don't mean anything since we have chosen them randomly, but by the end of training, they will. By learning on existing data about the relations between users and movies, without having any other information, we will see that they still get some important features, and can isolate blockbusters from independent cinema, action movies from romance, and so on.\n",
    "\n",
    "We are now in a position that we can create our whole model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can write a model in PyTorch, we first need to learn the basics of object-oriented programming and Python. If you haven't done any object-oriented programming before, we will give you a quick introduction here, but we would recommend looking up a tutorial and getting some practice before moving on.\n",
    "\n",
    "The key idea in object-oriented programming is the *class*. We have been using classes throughout this book, such as `DataLoader`, `string`, and `Learner`. Python also makes it easy for us to create new classes. Here is an example of a simple class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example:\n",
    "    def __init__(self, a): self.a = a\n",
    "    def say(self,x): return f'Hello {self.a}, {x}.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important piece of this is the special method called `__init__` (pronounced *dunder init*). In Python, any method surrounded in double underscores like this is considered special. It indicates that there is some extra behavior associated with this method name. In the case of `__init__`, this is the method Python will call when your new object is created. So, this is where you can set up any state that needs to be initialized upon object creation. Any parameters included when the user constructs an instance of your class will be passed to the `__init__` method as parameters. Note that the first parameter to any method defined inside a class is `self`, so you can use this to set and get any attributes that you will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Sylvain, nice to meet you.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = Example('Sylvain')\n",
    "ex.say('nice to meet you')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that creating a new PyTorch module requires inheriting from `Module`. *Inheritance* is an important object-oriented concept that we will not discuss in detail here—in short, it means that we can add additional behavior to an existing class. PyTorch already provides a `Module` class, which provides some basic foundations that we want to build on. So, we add the name of this *superclass* after the name of the class that we are defining, as shown in the following example.\n",
    "\n",
    "The final thing that you need to know to create a new PyTorch module is that when your module is called, PyTorch will call a method in your class called `forward`, and will pass along to that any parameters that are included in the call. Here is the class defining our dot product model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProduct(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.movie_factors = Embedding(n_movies, n_factors)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        movies = self.movie_factors(x[:,1])\n",
    "        return (users * movies).sum(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't seen object-oriented programming before, then don't worry, you won't need to use it much in this book. We are just mentioning this approach here, because most online tutorials and documentation will use the object-oriented syntax.\n",
    "\n",
    "Note that the input of the model is a tensor of shape `batch_size x 2`, where the first column (`x[:, 0]`) contains the user IDs and the second column (`x[:, 1]`) contains the movie IDs. As explained before, we use the *embedding* layers to represent our matrices of user and movie latent factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = dls.one_batch()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined our architecture, and created our parameter matrices, we need to create a `Learner` to optimize our model. In the past we have used special functions, such as `vision_learner`, which set up everything for us for a particular application. Since we are doing things from scratch here, we will use the plain `Learner` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DotProduct(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to fit our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.323817</td>\n",
       "      <td>1.340935</td>\n",
       "      <td>04:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.017078</td>\n",
       "      <td>1.092095</td>\n",
       "      <td>02:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.873056</td>\n",
       "      <td>0.974699</td>\n",
       "      <td>03:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.762055</td>\n",
       "      <td>0.897630</td>\n",
       "      <td>03:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.719645</td>\n",
       "      <td>0.874279</td>\n",
       "      <td>02:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we can do to make this model a little bit better is to force those predictions to be between 0 and 5. For this, we just need to use `sigmoid_range`, like in <<chapter_multicat>>. One thing we discovered empirically is that it's better to have the range go a little bit over 5, so we use `(0, 5.5)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProduct(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.movie_factors = Embedding(n_movies, n_factors)\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        movies = self.movie_factors(x[:,1])\n",
    "        return sigmoid_range((users * movies).sum(dim=1), *self.y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='4' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      80.00% [4/5 00:26&lt;00:06]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.938609</td>\n",
       "      <td>0.993308</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>0.945030</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.464125</td>\n",
       "      <td>0.951018</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.358895</td>\n",
       "      <td>0.952974</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='1202' class='' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      96.16% [1202/1250 00:04&lt;00:00 0.3345]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m DotProduct(n_users, n_movies, \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      2\u001b[0m learn \u001b[38;5;241m=\u001b[39m Learner(dls, model, loss_func\u001b[38;5;241m=\u001b[39mMSELossFlat())\n\u001b[0;32m----> 3\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_one_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5e-3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/fastai/callback/schedule.py:121\u001b[0m, in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    118\u001b[0m lr_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([h[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mhypers])\n\u001b[1;32m    119\u001b[0m scheds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, lr_max\u001b[38;5;241m/\u001b[39mdiv, lr_max, lr_max\u001b[38;5;241m/\u001b[39mdiv_final),\n\u001b[1;32m    120\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmom\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, \u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoms \u001b[38;5;28;01mif\u001b[39;00m moms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m moms))}\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParamScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_opt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/fastai/learner.py:266\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 266\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/fastai/learner.py:255\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 255\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/fastai/learner.py:249\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/fastai/learner.py:241\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/fastai/learner.py:207\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/fastai/data/load.py:129\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_iter()\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__idxs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_idxs() \u001b[38;5;66;03m# called in context of main process (not workers/subprocesses)\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_l\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pin_memory causes tuples to be converted to lists, so convert them back to tuples\u001b[39;49;00m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mto_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:42\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_iter)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/fastai/data/load.py:140\u001b[0m, in \u001b[0;36mDataLoader.create_batches\u001b[0;34m(self, samps)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m    139\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m o:o \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_item, samps))\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunkify(res))\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/fastai/data/load.py:185\u001b[0m, in \u001b[0;36mDataLoader.do_batch\u001b[0;34m(self, b)\u001b[0m\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, b): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretain(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, b)\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/fastai/tabular/core.py:357\u001b[0m, in \u001b[0;36mTabDataLoader.create_batch\u001b[0;34m(self, b)\u001b[0m\n\u001b[0;32m--> 357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, b): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/fastai/tabular/core.py:143\u001b[0m, in \u001b[0;36m_TabIloc.__getitem__\u001b[0;34m(self, idxs)\u001b[0m\n\u001b[1;32m    141\u001b[0m     cols \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39misin(cols) \u001b[38;5;28;01mif\u001b[39;00m is_listy(cols) \u001b[38;5;28;01melse\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(cols)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: rows,cols \u001b[38;5;241m=\u001b[39m idxs,\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto\u001b[38;5;241m.\u001b[39mnew(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1694\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n\u001b[0;32m-> 1694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple_same_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1020\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[1;32m   1018\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 1020\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1743\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1747\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1714\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1697\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;124;03mReturn Series values by list or array of integers.\u001b[39;00m\n\u001b[1;32m   1699\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;124;03m`axis` can only be zero.\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1716\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   4143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   4144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4145\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4146\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4154\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   4155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4131\u001b[0m     )\n\u001b[0;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4140\u001b[0m )\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repositories/other/fastbook/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:698\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    689\u001b[0m             indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    696\u001b[0m     ]\n\u001b[0;32m--> 698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n\u001b[1;32m    701\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(new_blocks, new_axes)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = DotProduct(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a reasonable start, but we can do better. One obvious missing piece is that some users are just more positive or negative in their recommendations than others, and some movies are just plain better or worse than others. But in our dot product representation we do not have any way to encode either of these things. If all you can say about a movie is, for instance, that it is very sci-fi, very action-oriented, and very not old, then you don't really have any way to say whether most people like it. \n",
    "\n",
    "That's because at this point we only have weights; we do not have biases. If we have a single number for each user that we can add to our scores, and ditto for each movie, that will handle this missing piece very nicely. So first of all, let's adjust our model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductBias(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.user_bias = Embedding(n_users, 1)\n",
    "        self.movie_factors = Embedding(n_movies, n_factors)\n",
    "        self.movie_bias = Embedding(n_movies, 1)\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        movies = self.movie_factors(x[:,1])\n",
    "        res = (users * movies).sum(dim=1, keepdim=True)\n",
    "        res += self.user_bias(x[:,0]) + self.movie_bias(x[:,1])\n",
    "        return sigmoid_range(res, *self.y_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try training this and see how it goes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DotProductBias(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of being better, it ends up being worse (at least at the end of training). Why is that? If we look at both trainings carefully, we can see the validation loss stopped improving in the middle and started to get worse. As we've seen, this is a clear indication of overfitting. In this case, there is no way to use data augmentation, so we will have to use another regularization technique. One approach that can be helpful is *weight decay*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight decay, or *L2 regularization*, consists in adding to your loss function the sum of all the weights squared. Why do that? Because when we compute the gradients, it will add a contribution to them that will encourage the weights to be as small as possible.\n",
    "\n",
    "Why would it prevent overfitting? The idea is that the larger the coefficients are, the sharper canyons we will have in the loss function. If we take the basic example of a parabola, `y = a * (x**2)`, the larger `a` is, the more *narrow* the parabola is (<<parabolas>>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#hide_input\n",
    "#id parabolas\n",
    "x = np.linspace(-2,2,100)\n",
    "a_s = [1,2,5,10,50] \n",
    "ys = [a * x**2 for a in a_s]\n",
    "_,ax = plt.subplots(figsize=(8,6))\n",
    "for a,y in zip(a_s,ys): ax.plot(x,y, label=f'a={a}')\n",
    "ax.set_ylim([0,5])\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, letting our model learn high parameters might cause it to fit all the data points in the training set with an overcomplex function that has very sharp changes, which will lead to overfitting.\n",
    "\n",
    "Limiting our weights from growing too much is going to hinder the training of the model, but it will yield a state where it generalizes better. Going back to the theory briefly, weight decay (or just `wd`) is a parameter that controls that sum of squares we add to our loss (assuming `parameters` is a tensor of all parameters):\n",
    "\n",
    "``` python\n",
    "loss_with_wd = loss + wd * (parameters**2).sum()\n",
    "```\n",
    "\n",
    "In practice, though, it would be very inefficient (and maybe numerically unstable) to compute that big sum and add it to the loss. If you remember a little bit of high school math, you might recall that the derivative of `p**2` with respect to `p` is `2*p`, so adding that big sum to our loss is exactly the same as doing:\n",
    "\n",
    "``` python\n",
    "parameters.grad += wd * 2 * parameters\n",
    "```\n",
    "\n",
    "In practice, since `wd` is a parameter that we choose, we can just make it twice as big, so we don't even need the `*2` in this equation. To use weight decay in fastai, just pass `wd` in your call to `fit` or `fit_one_cycle`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DotProductBias(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Our Own Embedding Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've used `Embedding` without thinking about how it really works. Let's re-create `DotProductBias` *without* using this class. We'll need a randomly initialized weight matrix for each of the embeddings. We have to be careful, however. Recall from <<chapter_mnist_basics>> that optimizers require that they can get all the parameters of a module from the module's `parameters` method. However, this does not happen fully automatically. If we just add a tensor as an attribute to a `Module`, it will not be included in `parameters`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T(Module):\n",
    "    def __init__(self): self.a = torch.ones(3)\n",
    "\n",
    "L(T().parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tell `Module` that we want to treat a tensor as a parameter, we have to wrap it in the `nn.Parameter` class. This class doesn't actually add any functionality (other than automatically calling `requires_grad_` for us). It's only used as a \"marker\" to show what to include in `parameters`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T(Module):\n",
    "    def __init__(self): self.a = nn.Parameter(torch.ones(3))\n",
    "\n",
    "L(T().parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All PyTorch modules use `nn.Parameter` for any trainable parameters, which is why we haven't needed to explicitly use this wrapper up until now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T(Module):\n",
    "    def __init__(self): self.a = nn.Linear(1, 3, bias=False)\n",
    "\n",
    "t = T()\n",
    "L(t.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(t.a.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a tensor as a parameter, with random initialization, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_params(size):\n",
    "    return nn.Parameter(torch.zeros(*size).normal_(0, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this to create `DotProductBias` again, but without `Embedding`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductBias(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
    "        self.user_factors = create_params([n_users, n_factors])\n",
    "        self.user_bias = create_params([n_users])\n",
    "        self.movie_factors = create_params([n_movies, n_factors])\n",
    "        self.movie_bias = create_params([n_movies])\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors[x[:,0]]\n",
    "        movies = self.movie_factors[x[:,1]]\n",
    "        res = (users*movies).sum(dim=1)\n",
    "        res += self.user_bias[x[:,0]] + self.movie_bias[x[:,1]]\n",
    "        return sigmoid_range(res, *self.y_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's train it again to check we get around the same results we saw in the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DotProductBias(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at what our model has learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting Embeddings and Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is already useful, in that it can provide us with movie recommendations for our users—but it is also interesting to see what parameters it has discovered. The easiest to interpret are the biases. Here are the movies with the lowest values in the bias vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_bias = learn.model.movie_bias.squeeze()\n",
    "idxs = movie_bias.argsort()[:5]\n",
    "[dls.classes['title'][i] for i in idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about what this means. What it's saying is that for each of these movies, even when a user is very well matched to its latent factors (which, as we will see in a moment, tend to represent things like level of action, age of movie, and so forth), they still generally don't like it. We could have simply sorted the movies directly by their average rating, but looking at the learned bias tells us something much more interesting. It tells us not just whether a movie is of a kind that people tend not to enjoy watching, but that people tend not to like watching it even if it is of a kind that they would otherwise enjoy! By the same token, here are the movies with the highest bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = movie_bias.argsort(descending=True)[:5]\n",
    "[dls.classes['title'][i] for i in idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for instance, even if you don't normally enjoy detective movies, you might enjoy *LA Confidential*!\n",
    "\n",
    "It is not quite so easy to directly interpret the embedding matrices. There are just too many factors for a human to look at. But there is a technique that can pull out the most important underlying *directions* in such a matrix, called *principal component analysis* (PCA). We will not be going into this in detail in this book, because it is not particularly important for you to understand to be a deep learning practitioner, but if you are interested then we suggest you check out the fast.ai course [Computational Linear Algebra for Coders](https://github.com/fastai/numerical-linear-algebra). <<img_pca_movie>> shows what our movies look like based on two of the strongest PCA components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#hide_input\n",
    "#id img_pca_movie\n",
    "#caption Representation of movies based on two strongest PCA components\n",
    "#alt Representation of movies based on two strongest PCA components\n",
    "g = ratings.groupby('title')['rating'].count()\n",
    "top_movies = g.sort_values(ascending=False).index.values[:1000]\n",
    "top_idxs = tensor([learn.dls.classes['title'].o2i[m] for m in top_movies])\n",
    "movie_w = learn.model.movie_factors[top_idxs].cpu().detach()\n",
    "movie_pca = movie_w.pca(3)\n",
    "fac0,fac1,fac2 = movie_pca.t()\n",
    "idxs = list(range(50))\n",
    "X = fac0[idxs]\n",
    "Y = fac2[idxs]\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(X, Y)\n",
    "for i, x, y in zip(top_movies[idxs], X, Y):\n",
    "    plt.text(x,y,i, color=np.random.rand(3)*0.7, fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the model seems to have discovered a concept of *classic* versus *pop culture* movies, or perhaps it is *critically acclaimed* that is represented here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> j: No matter how many models I train, I never stop getting moved and surprised by how these randomly initialized bunches of numbers, trained with such simple mechanics, manage to discover things about my data all by themselves. It almost seems like cheating, that I can create code that does useful things without ever actually telling it how to do those things!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined our model from scratch to teach you what is inside, but you can directly use the fastai library to build it. We'll look at how to do that next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using fastai.collab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create and train a collaborative filtering model using the exact structure shown earlier by using fastai's `collab_learner`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = collab_learner(dls, n_factors=50, y_range=(0, 5.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of the layers can be seen by printing the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these to replicate any of the analyses we did in the previous section—for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_bias = learn.model.i_bias.weight.squeeze()\n",
    "idxs = movie_bias.argsort(descending=True)[:5]\n",
    "[dls.classes['title'][i] for i in idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting thing we can do with these learned embeddings is to look at _distance_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a two-dimensional map we can calculate the distance between two coordinates using the formula of Pythagoras: $\\sqrt{x^{2}+y^{2}}$ (assuming that *x* and *y* are the distances between the coordinates on each axis). For a 50-dimensional embedding we can do exactly the same thing, except that we add up the squares of all 50 of the coordinate distances.\n",
    "\n",
    "If there were two movies that were nearly identical, then their embedding vectors would also have to be nearly identical, because the users that would like them would be nearly exactly the same. There is a more general idea here: movie similarity can be defined by the similarity of users that like those movies. And that directly means that the distance between two movies' embedding vectors can define that similarity. We can use this to find the most similar movie to *Silence of the Lambs*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_factors = learn.model.i_weight.weight\n",
    "idx = dls.classes['title'].o2i['Silence of the Lambs, The (1991)']\n",
    "distances = nn.CosineSimilarity(dim=1)(movie_factors, movie_factors[idx][None])\n",
    "idx = distances.argsort(descending=True)[1]\n",
    "dls.classes['title'][idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have succesfully trained a model, let's see how to deal with the situation where we have no data for a user. How can we make recommendations to new users?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping a Collaborative Filtering Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest challenge with using collaborative filtering models in practice is the *bootstrapping problem*. The most extreme version of this problem is when you have no users, and therefore no history to learn from. What products do you recommend to your very first user?\n",
    "\n",
    "But even if you are a well-established company with a long history of user transactions, you still have the question: what do you do when a new user signs up? And indeed, what do you do when you add a new product to your portfolio? There is no magic solution to this problem, and really the solutions that we suggest are just variations of *use your common sense*. You could assign new users the mean of all of the embedding vectors of your other users, but this has the problem that that particular combination of latent factors may be not at all common (for instance, the average for the science-fiction factor may be high, and the average for the action factor may be low, but it is not that common to find people who like science-fiction without action). Better would probably be to pick some particular user to represent *average taste*.\n",
    "\n",
    "Better still is to use a tabular model based on user meta data to construct your initial embedding vector. When a user signs up, think about what questions you could ask them that could help you to understand their tastes. Then you can create a model where the dependent variable is a user's embedding vector, and the independent variables are the results of the questions that you ask them, along with their signup metadata. We will see in the next section how to create these kinds of tabular models. (You may have noticed that when you sign up for services such as Pandora and Netflix, they tend to ask you a few questions about what genres of movie or music you like; this is how they come up with your initial collaborative filtering recommendations.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to be careful of is that a small number of extremely enthusiastic users may end up effectively setting the recommendations for your whole user base. This is a very common problem, for instance, in movie recommendation systems. People that watch anime tend to watch a whole lot of it, and don't watch very much else, and spend a lot of time putting their ratings on websites. As a result, anime tends to be heavily overrepresented in a lot of *best ever movies* lists. In this particular case, it can be fairly obvious that you have a problem of representation bias, but if the bias is occurring in the latent factors then it may not be obvious at all.\n",
    "\n",
    "Such a problem can change the entire makeup of your user base, and the behavior of your system. This is particularly true because of positive feedback loops. If a small number of your users tend to set the direction of your recommendation system, then they are naturally going to end up attracting more people like them to your system. And that will, of course, amplify the original representation bias. This type of bias has a natural tendency to be amplified exponentially. You may have seen examples of company executives expressing surprise at how their online platforms rapidly deteriorated in such a way that they expressed values at odds with the values of the founders. In the presence of these kinds of feedback loops, it is easy to see how such a divergence can happen both quickly and in a way that is hidden until it is too late.\n",
    "\n",
    "In a self-reinforcing system like this, we should probably expect these kinds of feedback loops to be the norm, not the exception. Therefore, you should assume that you will see them, plan for that, and identify up front how you will deal with these issues. Try to think about all of the ways in which feedback loops may be represented in your system, and how you might be able to identify them in your data. In the end, this is coming back to our original advice about how to avoid disaster when rolling out any kind of machine learning system. It's all about ensuring that there are humans in the loop; that there is careful monitoring, and a gradual and thoughtful rollout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dot product model works quite well, and it is the basis of many successful real-world recommendation systems. This approach to collaborative filtering is known as *probabilistic matrix factorization* (PMF). Another approach, which generally works similarly well given the same data, is deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning for Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn our architecture into a deep learning model, the first step is to take the results of the embedding lookup and concatenate those activations together. This gives us a matrix which we can then pass through linear layers and nonlinearities in the usual way.\n",
    "\n",
    "Since we'll be concatenating the embeddings, rather than taking their dot product, the two embedding matrices can have different sizes (i.e., different numbers of latent factors). fastai has a function `get_emb_sz` that returns recommended sizes for embedding matrices for your data, based on a heuristic that fast.ai has found tends to work well in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = get_emb_sz(dls)\n",
    "embs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement this class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollabNN(Module):\n",
    "    def __init__(self, user_sz, item_sz, y_range=(0,5.5), n_act=100):\n",
    "        self.user_factors = Embedding(*user_sz)\n",
    "        self.item_factors = Embedding(*item_sz)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(user_sz[1]+item_sz[1], n_act),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_act, 1))\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embs = self.user_factors(x[:,0]),self.item_factors(x[:,1])\n",
    "        x = self.layers(torch.cat(embs, dim=1))\n",
    "        return sigmoid_range(x, *self.y_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use it to create a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CollabNN(*embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CollabNN` creates our `Embedding` layers in the same way as previous classes in this chapter, except that we now use the `embs` sizes. `self.layers` is identical to the mini-neural net we created in <<chapter_mnist_basics>> for MNIST. Then, in `forward`, we apply the embeddings, concatenate the results, and pass this through the mini-neural net. Finally, we apply `sigmoid_range` as we have in previous models.\n",
    "\n",
    "Let's see if it trains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai provides this model in `fastai.collab` if you pass `use_nn=True` in your call to `collab_learner` (including calling `get_emb_sz` for you), and it lets you easily create more layers. For instance, here we're creating two hidden layers, of size 100 and 50, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = collab_learner(dls, use_nn=True, y_range=(0, 5.5), layers=[100,50])\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`learn.model` is an object of type `EmbeddingNN`. Let's take a look at fastai's code for this class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delegates(TabularModel)\n",
    "class EmbeddingNN(TabularModel):\n",
    "    def __init__(self, emb_szs, layers, **kwargs):\n",
    "        super().__init__(emb_szs, layers=layers, n_cont=0, out_sz=1, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's not a lot of code! This class *inherits* from `TabularModel`, which is where it gets all its functionality from. In `__init__` it calls the same method in `TabularModel`, passing `n_cont=0` and `out_sz=1`; other than that, it only passes along whatever arguments it received."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sidebar: kwargs and Delegates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EmbeddingNN` includes `**kwargs` as a parameter to `__init__`. In Python `**kwargs` in a parameter list means \"put any additional keyword arguments into a dict called `kwargs`. And `**kwargs` in an argument list means \"insert all key/value pairs in the `kwargs` dict as named arguments here\". This approach is used in many popular libraries, such as `matplotlib`, in which the main `plot` function simply has the signature `plot(*args, **kwargs)`. The [`plot` documentation](https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot) says \"The `kwargs` are `Line2D` properties\" and then lists those properties.\n",
    "\n",
    "We're using `**kwargs` in `EmbeddingNN` to avoid having to write all the arguments to `TabularModel` a second time, and keep them in sync. However, this makes our API quite difficult to work with, because now Jupyter Notebook doesn't know what parameters are available. Consequently things like tab completion of parameter names and pop-up lists of signatures won't work.\n",
    "\n",
    "fastai resolves this by providing a special `@delegates` decorator, which automatically changes the signature of the class or function (`EmbeddingNN` in this case) to insert all of its keyword arguments into the signature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End sidebar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the results of `EmbeddingNN` are a bit worse than the dot product approach (which shows the power of carefully constructing an architecture for a domain), it does allow us to do something very important: we can now directly incorporate other user and movie information, date and time information, or any other information that may be relevant to the recommendation. That's exactly what `TabularModel` does. In fact, we've now seen that `EmbeddingNN` is just a `TabularModel`, with `n_cont=0` and `out_sz=1`. So, we'd better spend some time learning about `TabularModel`, and how to use it to get great results! We'll do that in the next chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first non-computer vision application, we looked at recommendation systems and saw how gradient descent can learn intrinsic factors or biases about items from a history of ratings. Those can then give us information about the data. \n",
    "\n",
    "We also built our first model in PyTorch. We will do a lot more of this in the next section of the book, but first, let's finish our dive into the other general applications of deep learning, continuing with tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What problem does collaborative filtering solve?\n",
    "1. How does it solve it?\n",
    "1. Why might a collaborative filtering predictive model fail to be a very useful recommendation system?\n",
    "1. What does a crosstab representation of collaborative filtering data look like?\n",
    "1. Write the code to create a crosstab representation of the MovieLens data (you might need to do some web searching!).\n",
    "1. What is a latent factor? Why is it \"latent\"?\n",
    "1. What is a dot product? Calculate a dot product manually using pure Python with lists.\n",
    "1. What does `pandas.DataFrame.merge` do?\n",
    "1. What is an embedding matrix?\n",
    "1. What is the relationship between an embedding and a matrix of one-hot-encoded vectors?\n",
    "1. Why do we need `Embedding` if we could use one-hot-encoded vectors for the same thing?\n",
    "1. What does an embedding contain before we start training (assuming we're not using a pretained model)?\n",
    "1. Create a class (without peeking, if possible!) and use it.\n",
    "1. What does `x[:,0]` return?\n",
    "1. Rewrite the `DotProduct` class (without peeking, if possible!) and train a model with it.\n",
    "1. What is a good loss function to use for MovieLens? Why? \n",
    "1. What would happen if we used cross-entropy loss with MovieLens? How would we need to change the model?\n",
    "1. What is the use of bias in a dot product model?\n",
    "1. What is another name for weight decay?\n",
    "1. Write the equation for weight decay (without peeking!).\n",
    "1. Write the equation for the gradient of weight decay. Why does it help reduce weights?\n",
    "1. Why does reducing weights lead to better generalization?\n",
    "1. What does `argsort` do in PyTorch?\n",
    "1. Does sorting the movie biases give the same result as averaging overall movie ratings by movie? Why/why not?\n",
    "1. How do you print the names and details of the layers in a model?\n",
    "1. What is the \"bootstrapping problem\" in collaborative filtering?\n",
    "1. How could you deal with the bootstrapping problem for new users? For new movies?\n",
    "1. How can feedback loops impact collaborative filtering systems?\n",
    "1. When using a neural network in collaborative filtering, why can we have different numbers of factors for movies and users?\n",
    "1. Why is there an `nn.Sequential` in the `CollabNN` model?\n",
    "1. What kind of model should we use if we want to add metadata about users and items, or information such as date and time, to a collaborative filtering model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Research\n",
    "\n",
    "1. Take a look at all the differences between the `Embedding` version of `DotProductBias` and the `create_params` version, and try to understand why each of those changes is required. If you're not sure, try reverting each change to see what happens. (NB: even the type of brackets used in `forward` has changed!)\n",
    "1. Find three other areas where collaborative filtering is being used, and find out what the pros and cons of this approach are in those areas.\n",
    "1. Complete this notebook using the full MovieLens dataset, and compare your results to online benchmarks. See if you can improve your accuracy. Look on the book's website and the fast.ai forum for ideas. Note that there are more columns in the full dataset—see if you can use those too (the next chapter might give you ideas).\n",
    "1. Create a model for MovieLens that works with cross-entropy loss, and compare it to the model in this chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
